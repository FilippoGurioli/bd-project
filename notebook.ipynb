{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc897058-f991-4ebe-9f6b-d163fdd0ddb2",
   "metadata": {},
   "source": [
    "# Big Data Project Notebook\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Name: NYC Taxi & Limousine Commission (TLC) Trip Record Data\n",
    "Source link: [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page?utm_source=chatgpt.com)\n",
    "\n",
    "## Main Job\n",
    "\n",
    "**Objective**: Analyze how tip generosity varies by pickup location and time of day, and identify the top pickup zones with the most generous passengers.\n",
    "\n",
    "### Plan\n",
    "\n",
    "#### Setup\n",
    "\n",
    "- clean up and select relevant columns\n",
    "- create derived columns (tip percentage, hour of day)\n",
    "\n",
    "#### Shuffles\n",
    "\n",
    "- join zones id with zone lookup table\n",
    "- aggregate per location and hour\n",
    "- aggregate per average tip percentage\n",
    "- order by average tip percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef455ac8-7d1f-48ba-bdef-065eb3386cfe",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Import libraries\n",
    "- Setup Spark\n",
    "- Load dataset in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8cce42a-5329-4886-865c-ef8ec554e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/30 18:28:54 WARN Utils: Your hostname, rioly, resolves to a loopback address: 127.0.1.1; using 192.168.1.4 instead (on interface wlan0)\n",
      "25/10/30 18:28:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/30 18:28:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips RDD count: 3475226\n",
      "Zones RDD count: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:============================================>              (3 + 1) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample trips: [(229, (datetime.datetime(2025, 1, 1, 0, 18, 38), 10.0, 3.0)), (236, (datetime.datetime(2025, 1, 1, 0, 32, 40), 5.1, 2.02)), (141, (datetime.datetime(2025, 1, 1, 0, 44, 4), 5.1, 2.0)), (244, (datetime.datetime(2025, 1, 1, 0, 14, 27), 7.2, 0.0)), (244, (datetime.datetime(2025, 1, 1, 0, 21, 34), 5.8, 0.0))]\n",
      "Sample zones: [(1, ('\"EWR\"', '\"Newark Airport\"')), (2, ('\"Queens\"', '\"Jamaica Bay\"')), (3, ('\"Bronx\"', '\"Allerton/Pelham Gardens\"')), (4, ('\"Manhattan\"', '\"Alphabet City\"')), (5, ('\"Staten Island\"', '\"Arden Heights\"'))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Import Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session and context\n",
    "conf = SparkConf().setAppName(\"NYC Taxi Analysis RDD\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "trip_file = \"sample_data/yellow_tripdata_2025-01.parquet\"\n",
    "zone_file = \"sample_data/taxi_zone_lookup.csv\"\n",
    "\n",
    "# Load datasets\n",
    "df_trips = spark.read.parquet(trip_file).select(\n",
    "    \"PULocationID\",\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"fare_amount\",\n",
    "    \"tip_amount\"\n",
    ")\n",
    "\n",
    "# Convert to RDD of tuples: (PULocationID, (pickup_datetime, fare_amount, tip_amount))\n",
    "rdd_trips = df_trips.rdd.map(lambda row: (\n",
    "    row['PULocationID'],\n",
    "    (row['tpep_pickup_datetime'], row['fare_amount'], row['tip_amount'])\n",
    "))\n",
    "\n",
    "rdd_zones = sc.textFile(zone_file)\n",
    "\n",
    "header = rdd_zones.first()\n",
    "rdd_zones = rdd_zones.filter(lambda line: line != header)\n",
    "\n",
    "# Convert CSV line into tuple: (LocationID, (Borough, Zone))\n",
    "def parse_zone(line):\n",
    "    parts = line.split(\",\")\n",
    "    return (int(parts[0]), (parts[1], parts[2]))\n",
    "\n",
    "rdd_zones = rdd_zones.map(parse_zone)\n",
    "\n",
    "# Health checks\n",
    "print(\"Trips RDD count:\", rdd_trips.count())\n",
    "print(\"Zones RDD count:\", rdd_zones.count())\n",
    "print(\"Sample trips:\", rdd_trips.take(5))\n",
    "print(\"Sample zones:\", rdd_zones.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e901de04-2c82-42ef-947f-126e4cf3cac0",
   "metadata": {},
   "source": [
    "# Main Job\n",
    "\n",
    "## Join Trip Data with Zone Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d605c7-4633-4eea-9757-76565fdd7455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched trips RDD count: 3475226\n",
      "Sample enriched trips: [(170, '\"Manhattan\"', '\"Murray Hill\"', datetime.datetime(2025, 1, 1, 0, 14, 47), 4.4, 2.35), (170, '\"Manhattan\"', '\"Murray Hill\"', datetime.datetime(2025, 1, 1, 0, 27, 19), 5.8, 0.0), (170, '\"Manhattan\"', '\"Murray Hill\"', datetime.datetime(2025, 1, 1, 0, 42, 44), 14.9, 3.98), (170, '\"Manhattan\"', '\"Murray Hill\"', datetime.datetime(2025, 1, 1, 0, 7, 28), 10.7, 2.83), (170, '\"Manhattan\"', '\"Murray Hill\"', datetime.datetime(2025, 1, 1, 0, 19, 2), 12.8, 3.55)]\n"
     ]
    }
   ],
   "source": [
    "rdd_joined = rdd_trips.join(rdd_zones)\n",
    "\n",
    "# Reformat for convenience: (PULocationID, Borough, Zone, pickup_dt, fare, tip)\n",
    "rdd_enriched = rdd_joined.map(lambda x: (\n",
    "    x[0],                     # PULocationID\n",
    "    x[1][1][0],               # Borough\n",
    "    x[1][1][1],               # Zone\n",
    "    x[1][0][0],               # pickup_datetime\n",
    "    x[1][0][1],               # fare_amount\n",
    "    x[1][0][2]                # tip_amount\n",
    "))\n",
    "\n",
    "# Health check\n",
    "print(\"Enriched trips RDD count:\", rdd_enriched.count())\n",
    "print(\"Sample enriched trips:\", rdd_enriched.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec394b8-4412-4b91-9196-3d398fe78dca",
   "metadata": {},
   "source": [
    "## Compute derived columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f43e05-696d-4e41-a63e-6950ee220d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample derived RDD: [(170, '\"Manhattan\"', '\"Murray Hill\"', 0, 4.4, 2.35, 53.40909090909091), (170, '\"Manhattan\"', '\"Murray Hill\"', 0, 5.8, 0.0, 0.0), (170, '\"Manhattan\"', '\"Murray Hill\"', 0, 14.9, 3.98, 26.711409395973153), (170, '\"Manhattan\"', '\"Murray Hill\"', 0, 10.7, 2.83, 26.448598130841123), (170, '\"Manhattan\"', '\"Murray Hill\"', 0, 12.8, 3.55, 27.734374999999993)]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Function to extract hour from datetime string\n",
    "def extract_hour(pickup_dt):\n",
    "    if isinstance(pickup_dt, str):\n",
    "        return datetime.strptime(pickup_dt, \"%Y-%m-%d %H:%M:%S\").hour\n",
    "    else:\n",
    "        return pickup_dt.hour  # if already datetime object\n",
    "\n",
    "# Compute tip percentage and pickup hour\n",
    "rdd_derived = rdd_enriched.map(lambda x: (\n",
    "    x[0],             # PULocationID\n",
    "    x[1],             # Borough\n",
    "    x[2],             # Zone\n",
    "    extract_hour(x[3]),       # pickup_hour\n",
    "    x[4],             # fare_amount\n",
    "    x[5],             # tip_amount\n",
    "    (x[5] / x[4] * 100) if x[4] != 0 else 0  # tip_pct\n",
    "))\n",
    "\n",
    "# RDD structure now:\n",
    "# (PULocationID, Borough, Zone, pickup_hour, fare_amount, tip_amount, tip_pct)\n",
    "\n",
    "# Health check\n",
    "print(\"Sample derived RDD:\", rdd_derived.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f841a-e74a-4ac4-b4e7-9009fe1df270",
   "metadata": {},
   "source": [
    "## Aggregate by Pickup Zone and Hour\n",
    "\n",
    "Foreach pickup zone and foreach hour, I compute the average tip percentage in that zone in that hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf720eb5-758f-4039-a56d-37f80d9ca8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:====================================================>   (16 + 1) / 17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample aggregated by hour RDD (naive): [(170, '\"Manhattan\"', '\"Murray Hill\"', 21, 18.73, 5005), (238, '\"Manhattan\"', '\"Upper West Side North\"', 7, 16.44, 3044), (238, '\"Manhattan\"', '\"Upper West Side North\"', 11, 20.57, 4464), (238, '\"Manhattan\"', '\"Upper West Side North\"', 22, 18.3, 1557), (255, '\"Brooklyn\"', '\"Williamsburg (North Side)\"', 5, 1.07, 21)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Map to key-value for aggregation\n",
    "rdd_for_agg = rdd_derived.map(lambda x: (\n",
    "    (x[0], x[1], x[2], x[3]),  # key = (PULocationID, Borough, Zone, pickup_hour)\n",
    "    x[6]                        # tip_pct\n",
    "))\n",
    "\n",
    "rdd_grouped = rdd_for_agg.groupByKey()\n",
    "\n",
    "rdd_agg_hour = rdd_grouped.map(lambda x: (\n",
    "    x[0][0],     # PULocationID\n",
    "    x[0][1],     # Borough\n",
    "    x[0][2],     # Zone\n",
    "    x[0][3],     # pickup_hour\n",
    "    round(sum(x[1])/len(list(x[1])), 2),  # avg_tip_pct\n",
    "    len(list(x[1]))                        # num_trips\n",
    "))\n",
    "\n",
    "# Health check\n",
    "print(\"Sample aggregated by hour RDD (naive):\", rdd_agg_hour.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac161cee-ef75-44ee-a41e-3702d0b8fb8a",
   "metadata": {},
   "source": [
    "## Aggregate Across Hours per Pickup Zone\n",
    "\n",
    "Foreach pickup zone, I compute the mean between all percentage tips for all hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4776f51d-008d-47da-87ec-e96e925c0c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample aggregated by zone RDD (overall): [(136, '\"Bronx\"', '\"Kingsbridge Heights\"', 0.58, 290), (1, '\"EWR\"', '\"Newark Airport\"', 31.73, 377), (87, '\"Manhattan\"', '\"Financial District North\"', 15.33, 18053), (121, '\"Queens\"', '\"Hillcrest/Pomonok\"', 1.1, 358), (243, '\"Manhattan\"', '\"Washington Heights North\"', 4.02, 1163)]\n"
     ]
    }
   ],
   "source": [
    "# Map to key-value for aggregation\n",
    "rdd_for_agg_zone = rdd_agg_hour.map(lambda x: (\n",
    "    (x[0], x[1], x[2]),   # key = (PULocationID, Borough, Zone)\n",
    "    (x[4], x[5])           # (avg_tip_pct, num_trips)\n",
    "))\n",
    "\n",
    "\n",
    "rdd_grouped_zone = rdd_for_agg_zone.groupByKey()\n",
    "\n",
    "rdd_agg_zone = rdd_grouped_zone.map(lambda x: (\n",
    "    x[0][0],  # PULocationID\n",
    "    x[0][1],  # Borough\n",
    "    x[0][2],  # Zone\n",
    "    round(sum(v[0] for v in x[1]) / len(list(x[1])), 2),  # avg_tip_pct_overall\n",
    "    sum(v[1] for v in x[1])                                # total_trips\n",
    "))\n",
    "\n",
    "# Health check\n",
    "print(\"Sample aggregated by zone RDD (overall):\", rdd_agg_zone.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b8229-1d9a-418c-9a59-1ee31f53dfe3",
   "metadata": {},
   "source": [
    "## Order by average tip percentage\n",
    "\n",
    "Once the computation is done, to obtain the greatest I just order the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c0d95d-f117-47fa-8a46-7bae68810d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 pickup zones by tip generosity:\n",
      "(265, '\"N/A\"', '\"Outside of NYC\"', 372.8, 1380)\n",
      "(29, '\"Brooklyn\"', '\"Brighton Beach\"', 136.37, 270)\n",
      "(23, '\"Staten Island\"', '\"Bloomfield/Emerson Hill\"', 115.15, 15)\n",
      "(1, '\"EWR\"', '\"Newark Airport\"', 31.73, 377)\n",
      "(22, '\"Brooklyn\"', '\"Bensonhurst West\"', 28.14, 345)\n",
      "(199, '\"Bronx\"', '\"Rikers Island\"', 25.05, 1)\n",
      "(264, '\"Unknown\"', '\"N/A\"', 22.87, 8141)\n",
      "(162, '\"Manhattan\"', '\"Midtown East\"', 22.18, 117930)\n",
      "(237, '\"Manhattan\"', '\"Upper East Side South\"', 21.53, 163703)\n",
      "(142, '\"Manhattan\"', '\"Lincoln Square East\"', 21.5, 110585)\n"
     ]
    }
   ],
   "source": [
    "rdd_top_zones = rdd_agg_zone.sortBy(lambda x: x[3], ascending=False) # avg_tip_pct_overall\n",
    "\n",
    "# Health check: show top 10 zones\n",
    "print(\"Top 10 pickup zones by tip generosity:\")\n",
    "for row in rdd_top_zones.take(10):\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e92fa2-15ad-4f5f-80f8-c4b106f6fc93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Optimized Job\n",
    "\n",
    "The following code assumes that the setup code has been executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06da6e82-59e2-48a2-876f-d9ba1400c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 pickup zones by tip percentage (optimized):\n",
      "\"Outside of NYC\" (\"N/A\", ID: 265) - Avg Tip: 372.80%\n",
      "\"Brighton Beach\" (\"Brooklyn\", ID: 29) - Avg Tip: 136.36%\n",
      "\"Bloomfield/Emerson Hill\" (\"Staten Island\", ID: 23) - Avg Tip: 115.15%\n",
      "\"Newark Airport\" (\"EWR\", ID: 1) - Avg Tip: 31.77%\n",
      "\"Bensonhurst West\" (\"Brooklyn\", ID: 22) - Avg Tip: 28.14%\n",
      "\"Rikers Island\" (\"Bronx\", ID: 199) - Avg Tip: 25.05%\n",
      "\"N/A\" (\"Unknown\", ID: 264) - Avg Tip: 22.86%\n",
      "\"Midtown East\" (\"Manhattan\", ID: 162) - Avg Tip: 22.19%\n",
      "\"Lincoln Square East\" (\"Manhattan\", ID: 142) - Avg Tip: 21.54%\n",
      "\"Upper East Side South\" (\"Manhattan\", ID: 237) - Avg Tip: 21.54%\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Broadcast the zones table\n",
    "zones_dict = dict(rdd_zones.collect())\n",
    "broadcast_zones = sc.broadcast(zones_dict)\n",
    "\n",
    "# Compute derived columns and aggregate\n",
    "def enrich_trip(trip):\n",
    "    pu_id, (pickup_dt, fare, tip) = trip\n",
    "    \n",
    "    if isinstance(pickup_dt, datetime):\n",
    "        hour = pickup_dt.hour\n",
    "    else:\n",
    "        try:\n",
    "            hour = datetime.strptime(str(pickup_dt), \"%Y-%m-%d %H:%M:%S\").hour\n",
    "        except:\n",
    "            hour = -1\n",
    "    try:\n",
    "        fare = float(fare)\n",
    "        tip = float(tip)\n",
    "    except:\n",
    "        fare, tip = 0.0, 0.0\n",
    "    \n",
    "    # Calculate tip percentage\n",
    "    tip_pct = (tip / fare * 100) if fare > 0 else 0.0\n",
    "    \n",
    "    # Get zone info from broadcast variable\n",
    "    borough, zone = broadcast_zones.value.get(pu_id, (\"Unknown\", \"Unknown\"))\n",
    "    \n",
    "    # Return key-value pair for aggregation\n",
    "    # Key: (PULocationID, Borough, Zone, hour)\n",
    "    # Value: (tip_pct, count)\n",
    "    return ((pu_id, borough, zone, hour), (tip_pct, 1))\n",
    "\n",
    "# Helper function to sum tip percentages and counts\n",
    "def sum_tip_count(a, b):\n",
    "    return (a[0] + b[0], a[1] + b[1])\n",
    "\n",
    "# Enrich trips and aggregate by (zone, hour)\n",
    "rdd_zone_hour_agg = rdd_trips.map(enrich_trip).reduceByKey(sum_tip_count)\n",
    "\n",
    "# Compute average tip per zone-hour\n",
    "rdd_zone_hour_avg = rdd_zone_hour_agg.map(\n",
    "    lambda kv: ((kv[0][0], kv[0][1], kv[0][2]), kv[1][0] / kv[1][1])\n",
    "    # Key: (PULocationID, Borough, Zone), Value: avg_tip_pct for that hour\n",
    ")\n",
    "\n",
    "# Partition before aggregating across hours (for better performance)\n",
    "num_partitions = 8\n",
    "rdd_zone_hour_avg = rdd_zone_hour_avg.partitionBy(\n",
    "    num_partitions, \n",
    "    partitionFunc=lambda key: hash(key[0])  # partition by PULocationID\n",
    ").cache()\n",
    "\n",
    "# Aggregate across all hours per zone to get overall average tip\n",
    "rdd_zone_agg = rdd_zone_hour_avg.map(lambda kv: (kv[0], (kv[1], 1))) \\\n",
    "    .reduceByKey(sum_tip_count) \\\n",
    "    .map(lambda kv: (kv[0], kv[1][0] / kv[1][1]))\n",
    "\n",
    "# Sort zones by descending average tip percentage\n",
    "rdd_top_zones = rdd_zone_agg.sortBy(lambda kv: kv[1], ascending=False)\n",
    "\n",
    "# Show top 10 zones\n",
    "print(\"Top 10 pickup zones by tip percentage (optimized):\")\n",
    "for zone_info, avg_tip in rdd_top_zones.take(10):\n",
    "    pu_id, borough, zone = zone_info\n",
    "    print(f\"{zone} ({borough}, ID: {pu_id}) - Avg Tip: {avg_tip:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
